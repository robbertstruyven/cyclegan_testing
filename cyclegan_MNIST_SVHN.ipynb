{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cyclegan_MNIST_SVHN_Robbert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toca_03QWLh-",
        "colab_type": "text"
      },
      "source": [
        "# Cyclegan Testing\n",
        "\n",
        "Based on **Transforming the World Into Paintings with CycleGAN** <br>\n",
        "Implementing a CycleGAN In Keras and Tensorflow 2.0: [link](https://medium.com/analytics-vidhya/transforming-the-world-into-paintings-with-cyclegan-6748c0b85632)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X98Py4KoQBNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OzG-MRwD8HgI",
        "colab": {}
      },
      "source": [
        "# For the 'InstanceNormalization' layer\n",
        "!pip install --upgrade tensorflow_addons\n",
        "# For the dataset\n",
        "!pip install --upgrade tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eWBg9-PI8SZG",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm_notebook as tqdm \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.layers import (Activation, Concatenate, Conv2D, BatchNormalization,\n",
        "                                     Conv2DTranspose, Input, LeakyReLU, PReLU, Dropout)\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMIgF26YUdT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd gdrive/My\\ Drive/Learning_Theory_Project/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6M8YY-58Sb6",
        "colab": {}
      },
      "source": [
        "# Load dataset: \n",
        "# Take a look here: https://www.tensorflow.org/datasets/catalog/cycle_gan\n",
        "\n",
        "# Which Setting\n",
        "#setting = 'mnist'\n",
        "#setting = 'orange'\n",
        "setting = 'monet'\n",
        "\n",
        "BUFFER_SIZE = 64\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "if setting == 'mnist': \n",
        "    data_mnist, metadata_mnist = tfds.load('mnist', with_info=True, as_supervised=True)\n",
        "    data_svhn , metadata_svhn  = tfds.load('svhn_cropped', with_info=True, as_supervised=True)\n",
        "\n",
        "    train_x, train_y, test_x, test_y = data_mnist['train'], data_svhn['train'], data_mnist['test'], data_svhn['test']\n",
        "\n",
        "    scaling = 8\n",
        "\n",
        "    img_rows, img_cols = int(256/scaling), int(256/scaling)\n",
        "    img_rows, img_cols = int(256/scaling), int(256/scaling)\n",
        "    channels = 3\n",
        "\n",
        "    # Normalize images to [-1, 1] and reshape\n",
        "    def preprocess_image_3(image, label):\n",
        "        return tf.reshape(tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))), tf.float32) / 127.5 - 1, (img_rows, img_cols, 3)), label\n",
        "\n",
        "    def preprocess_image_1(image, label):\n",
        "        return tf.tile(tf.reshape(tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))), tf.float32) / 127.5 - 1, (img_rows, img_cols, 1)), tf.constant([1, 1, 3])), label\n",
        "\n",
        "    # Map the normalization onto the dataset\n",
        "    train_x = train_x.map(preprocess_image_1, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    train_y = train_y.map(preprocess_image_3, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_x = test_x.map(preprocess_image_1, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_y = test_y.map(preprocess_image_3, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "\n",
        "    x_batch_image, x_batch_label = next(iter(train_x.batch(32)))\n",
        "    y_batch_image, y_batch_label = next(iter(train_y.batch(32)))\n",
        "\n",
        "    fig, ax = plt.subplots(2,4)\n",
        "    for i in range(4):\n",
        "      ax[0][i].imshow(x_batch_image[i][:,:,0])\n",
        "      ax[1][i].imshow(y_batch_image[i][:,:,0])\n",
        "      ax[0][i].set_title(x_batch_label[i].numpy())\n",
        "      ax[1][i].set_title(y_batch_label[i].numpy())\n",
        "      ax[0][i].axis('off')\n",
        "      ax[1][i].axis('off')\n",
        "\n",
        "elif setting == 'monet':\n",
        "  # monet2photo\n",
        "    data, metadata = tfds.load('cycle_gan/summer2winter_yosemite', with_info=True, as_supervised=True)\n",
        "    train_x, train_y, test_x, test_y = data['trainA'], data['trainB'], data['testA'], data['testB']\n",
        "    \n",
        "    scaling = 1\n",
        "    \n",
        "    img_rows, img_cols, channels = int(256/scaling), int(256/scaling), 3\n",
        "    # Normalize images to [-1, 1] and reshape\n",
        "    def preprocess_image(image, _):\n",
        "        return tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))), tf.float32) / 127.5 - 1 , _\n",
        "\n",
        "    # Map the normalization onto the dataset\n",
        "    train_x = train_x.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    train_y = train_y.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_x = test_x.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_y = test_y.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "\n",
        "elif setting == 'orange': \n",
        "    data, metadata = tfds.load('cycle_gan/apple2orange', with_info=True, as_supervised=True)\n",
        "    train_x, train_y, test_x, test_y = data['trainA'], data['trainB'], data['testA'], data['testB']\n",
        "    \n",
        "    scaling = 1\n",
        "    \n",
        "    img_rows, img_cols, channels = int(256/scaling), int(256/scaling), 3\n",
        "    # Normalize images to [-1, 1] and reshape\n",
        "    def preprocess_image(image, _):\n",
        "        return tf.cast(tf.image.resize(image, (int(img_rows), int(img_cols))), tf.float32) / 127.5 - 1 , _\n",
        "\n",
        "    # Map the normalization onto the dataset\n",
        "    train_x = train_x.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    train_y = train_y.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_x = test_x.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "    test_y = test_y.map(preprocess_image, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE)\n",
        "\n",
        "else:\n",
        "  raise ValueError('ERROR : SETTING should be mnist, monet OR orange.')\n",
        "\n",
        "\n",
        "# Pre-loading old weights \n",
        "hot_start = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hq6Knn_C8SgY",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tq1rsy-o8SeN",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "LAMBDA = 5\n",
        "LAMBDA2 = 5\n",
        "\n",
        "weight_initializer = RandomNormal(stddev=0.02)\n",
        "\n",
        "optimizer = 'Adam'\n",
        "#optimizer = 'RMSprop'\n",
        "\n",
        "if optimizer == 'Adam':\n",
        "  gen_g_optimizer = gen_f_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "  dis_x_optimizer = dis_y_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
        "elif optimizer == 'Adam2':\n",
        "  gen_g_optimizer = gen_f_optimizer = Adam(lr=0.001, beta_1=0.5)\n",
        "  dis_x_optimizer = dis_y_optimizer = Adam(lr=0.001, beta_1=0.5)\n",
        "elif optimizer == 'RMSprop':\n",
        "  gen_g_optimizer = gen_f_optimizer = RMSprop(lr=0.0002, momentum=0.5 )\n",
        "  dis_x_optimizer = dis_y_optimizer = RMSprop(lr=0.0002, momentum=0.5 )\n",
        "else:\n",
        "  raise ValueError('ERROR : Optimizer should be Adam or RMSprop!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZG9um_J8SmD",
        "colab": {}
      },
      "source": [
        "use_instancenorm = False\n",
        "\n",
        "# \"Ck denotes a 4 × 4 Convolution-InstanceNorm-LeakyReLU layer with k filters and stride 2\n",
        "def Ck(input, k, use_instancenorm=True, start = False):\n",
        "    block = Conv2D(k, (4, 4), strides=2, padding='same', kernel_initializer=weight_initializer)(input)\n",
        "    if not start : \n",
        "      if use_instancenorm:\n",
        "        block = InstanceNormalization(axis=-1)(block)\n",
        "      else:\n",
        "       block = BatchNormalization()(block)\n",
        "    # Old code used LeakyRelu(0.2)\n",
        "    block = LeakyReLU(0.2)(block)\n",
        "    #block = PReLU()(block)\n",
        "\n",
        "    return block\n",
        "\n",
        "# C64, C128, C256, C512\n",
        "def discriminator():\n",
        "    dis_input = Input(shape=(img_rows, img_cols, channels))\n",
        "\n",
        "    d = Ck(dis_input, 64, use_instancenorm, start = True)\n",
        "    d = Ck(d, 128, use_instancenorm)\n",
        "    d = Ck(d, 256, use_instancenorm)\n",
        "    d = Ck(d, 512, use_instancenorm)\n",
        "\n",
        "    d = Conv2D(1, (4, 4), padding='same', kernel_initializer=weight_initializer)(d)\n",
        "\n",
        "    return Model(dis_input, d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByAGo-Uc8SoS",
        "colab": {}
      },
      "source": [
        "# \"dk denotes a 3×3 Convolution-InstanceNorm-ReLU with k filters and stride 2\"\n",
        "def dk(k, use_instancenorm=True, start = False):\n",
        "    block = Sequential()\n",
        "    block.add(Conv2D(k, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer))\n",
        "    if not start:\n",
        "        if use_instancenorm:\n",
        "            block.add(InstanceNormalization(axis=-1))\n",
        "        else:\n",
        "            block.add(BatchNormalization())\n",
        "    # changed relu to lrelu\n",
        "    block.add(Activation(tf.nn.relu))\n",
        "\n",
        "    return block\n",
        "\n",
        "# \"uk denotes a 3×3 fractional-strided-ConvolutionInstanceNorm-ReLU layer with k filters and stride ½\"\n",
        "def uk(k, use_instancenorm=True, start = False, apply_dropout=False):\n",
        "    block = Sequential()\n",
        "    block.add(Conv2DTranspose(k, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer))\n",
        "    if not start:\n",
        "        if use_instancenorm:\n",
        "            block.add(InstanceNormalization(axis=-1))\n",
        "        else:\n",
        "            block.add(BatchNormalization())\n",
        "        if apply_dropout:\n",
        "            block.add(Dropout(0.5))\n",
        "    # changed relu to lrelu\n",
        "    block.add(Activation(tf.nn.relu))\n",
        "\n",
        "    return block\n",
        "\n",
        "def generator():\n",
        "    gen_input = Input(shape=(img_rows, img_cols, channels))\n",
        "    \n",
        "    # Layers for the encoder part of the model\n",
        "    encoder_layers = [\n",
        "        dk(64, use_instancenorm, start = True),\n",
        "        dk(128, use_instancenorm),\n",
        "        dk(256, use_instancenorm),\n",
        "        dk(256, use_instancenorm),\n",
        "        dk(512, use_instancenorm),\n",
        "        dk(512, use_instancenorm),\n",
        "        dk(512, use_instancenorm),\n",
        "        dk(512, use_instancenorm),\n",
        "        dk(512, use_instancenorm)\n",
        "    ]\n",
        "\n",
        "    # Layers for the decoder part of the model\n",
        "    decoder_layers = [\n",
        "        uk(512, use_instancenorm, apply_dropout=True),\n",
        "        uk(512, use_instancenorm, apply_dropout=True),\n",
        "        uk(512, use_instancenorm, apply_dropout=True),\n",
        "        uk(512, use_instancenorm),\n",
        "        uk(256, use_instancenorm),\n",
        "        uk(256, use_instancenorm),\n",
        "        uk(128, use_instancenorm),\n",
        "        uk(64 , use_instancenorm)\n",
        "    ]\n",
        "\n",
        "    gen = gen_input\n",
        "\n",
        "    # Add all the encoder layers, and keep track of them for skip connections\n",
        "    skips = []\n",
        "    for layer in encoder_layers:\n",
        "        gen = layer(gen)\n",
        "        skips.append(gen)\n",
        "    \n",
        "    skips = skips[::-1][1:] # Reverse for looping and get rid of the layer that directly connects to decoder\n",
        "\n",
        "    # Add all the decoder layers and skip connections\n",
        "    for skip_layer, layer in zip(skips, decoder_layers):\n",
        "        gen = layer(gen)\n",
        "        gen = Concatenate()([gen, skip_layer])\n",
        "    \n",
        "    # Final layer\n",
        "    gen = Conv2DTranspose(channels, (3, 3), strides=2, padding='same', kernel_initializer=weight_initializer, activation='tanh')(gen)\n",
        "    \n",
        "    # Compose model\n",
        "    return Model(gen_input, gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7ZZOaJKkIAT2",
        "colab": {}
      },
      "source": [
        "# Define the models\n",
        "generator_g = generator()\n",
        "generator_f = generator()\n",
        "\n",
        "discriminator_x = discriminator()\n",
        "discriminator_y = discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8s-DdUc68Sqs",
        "colab": {}
      },
      "source": [
        " # Losses\n",
        "loss = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Measures how close to one real images are rated, and how close to zero fake images are rated\n",
        "def discriminator_loss(real, generated):\n",
        "    return ( loss(tf.ones_like(real) + tf.random.normal(real.shape,\n",
        "                                                        mean=0.0, \n",
        "                                                        stddev=.1, \n",
        "                                                        dtype=tf.dtypes.float32) , real) + \\\n",
        "            loss(tf.zeros_like(generated) + tf.random.normal(generated.shape,mean=0.0, \n",
        "                                                             stddev=.1,\n",
        "                                                             dtype=tf.dtypes.float32), generated) )\n",
        "\n",
        "# Measures how real the discriminator believes the fake image is\n",
        "def gen_loss(validity):\n",
        "    return loss(tf.ones_like(validity) + tf.random.normal(validity.shape,\n",
        "                                                          mean=0.0, \n",
        "                                                          stddev=.1, \n",
        "                                                          dtype=tf.dtypes.float32) , validity)\n",
        "\n",
        "# Measures similarity of two images.  Used for cycle and identity loss\n",
        "def image_similarity(image1, image2):\n",
        "    return tf.reduce_mean(tf.abs(image1 - image2))\n",
        "\n",
        "# CHANGE : FEATURIZER\n",
        "#featurizer = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "#for layer in featurizer.layers:\n",
        "#    layer.trainable = False\n",
        "\n",
        "# Measures similarity of two images.  Used for cycle and identity loss\n",
        "#def pixel_image_similarity(image1, image2):\n",
        "#    return tf.reduce_mean(tf.abs(image1 - image2))\n",
        "\n",
        "# Measures similarity of two images.  Used for cycle and identity loss\n",
        "#def featurizer_similarity(image1, image2):\n",
        "#    image1_rep = featurizer(image1)\n",
        "#    image2_rep = featurizer(image2)\n",
        "#    return pixel_image_similarity(image1_rep, image2_rep)\n",
        "\n",
        "#pixel_weight = tf.Variable(0.9)\n",
        "#def image_similarity(image1, image2):\n",
        "#    return pixel_weight * pixel_image_similarity(image1, image2)\\\n",
        "#           + (1 - pixel_weight) * featurizer_similarity(image1, image2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De0lfCo4t62o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upscale_discriminator = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WYUJS3CF8Ss7",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def step(real_x, real_y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Discriminator upscaling\n",
        "        \n",
        "        # Setup Dy loss\n",
        "        fake_y = generator_g(real_x, training=True)\n",
        "        gen_g_validity = discriminator_y(fake_y, training=True)*upscale_discriminator\n",
        "        dis_y_loss = discriminator_loss(discriminator_y(real_y, training=True), gen_g_validity)\n",
        "\n",
        "        with tape.stop_recording():\n",
        "            discriminator_y_gradients = tape.gradient(dis_y_loss, discriminator_y.trainable_variables)\n",
        "            dis_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
        "\n",
        "        # Setup Dx loss\n",
        "        fake_x = generator_f(real_y, training=True)\n",
        "        gen_f_validity = discriminator_x(fake_x, training=True)*upscale_discriminator\n",
        "        dis_x_loss = discriminator_loss(discriminator_x(real_x, training=True), gen_f_validity)\n",
        "\n",
        "        with tape.stop_recording():\n",
        "            discriminator_x_gradients = tape.gradient(dis_x_loss, discriminator_x.trainable_variables)\n",
        "            dis_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "\n",
        "        # Setup adversarial losses\n",
        "        gen_g_adv_loss = gen_loss(gen_g_validity)\n",
        "        gen_f_adv_loss = gen_loss(gen_f_validity)\n",
        "\n",
        "        # Setup cycle losses\n",
        "        cyc_x = generator_f(fake_y, training=True)\n",
        "        cyc_x_loss = image_similarity(real_x, cyc_x)\n",
        "\n",
        "        cyc_y = generator_g(fake_x, training=True)\n",
        "        cyc_y_loss =  image_similarity(real_y, cyc_y)\n",
        "\n",
        "        # Setup identity losses\n",
        "        id_x = generator_f(real_x, training=True)\n",
        "        id_x_loss = image_similarity(real_x, id_x)\n",
        "\n",
        "        id_y = generator_g(real_y, training=True)\n",
        "        id_y_loss = image_similarity(real_y, id_y)\n",
        "\n",
        "        # Finalize generator losses and calc gradients\n",
        "        gen_g_loss = gen_g_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_y_loss * LAMBDA2 * 0.5 \n",
        "        gen_f_loss = gen_f_adv_loss + (cyc_x_loss + cyc_y_loss) * LAMBDA + id_x_loss * LAMBDA2 * 0.5 \n",
        "\n",
        "        with tape.stop_recording():\n",
        "            generator_g_gradients = tape.gradient(gen_g_loss, generator_g.trainable_variables)\n",
        "            gen_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
        "\n",
        "            generator_f_gradients = tape.gradient(gen_f_loss, generator_f.trainable_variables)\n",
        "            gen_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uO62UsfgFYn1",
        "colab": {}
      },
      "source": [
        "def generate_images(size=1):\n",
        "    # Sample images\n",
        "    x, _ = next(iter(test_x.shuffle(1000)))\n",
        "    y, _ = next(iter(test_y.shuffle(1000)))\n",
        "\n",
        "    x = x.numpy().reshape((1, img_rows, img_cols, channels))\n",
        "    y = y.numpy().reshape((1, img_rows, img_cols, channels))\n",
        "    \n",
        "    # Get predictions for those images\n",
        "    y_hat = generator_g.predict(x.reshape((1, img_rows, img_cols, channels)))\n",
        "    x_hat = generator_f.predict(y.reshape((1, img_rows, img_cols, channels)))\n",
        "    \n",
        "    plt.figure(figsize=(7*size, 15*size))\n",
        "\n",
        "    images = [x[0], y_hat[0], y[0], x_hat[0]]\n",
        "\n",
        "    for i in range(4):\n",
        "        plt.subplot(1, 4, i+1)\n",
        "        plt.imshow(images[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for _ in range(1):\n",
        "    generate_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0BiuN-nB6mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images2(size=1, name = None):\n",
        "    # Sample images\n",
        "    x, _ = next(iter(test_x.shuffle(1000)))\n",
        "    y, _ = next(iter(test_y.shuffle(1000)))\n",
        "\n",
        "    x = x.numpy().reshape((1, img_rows, img_cols, channels))\n",
        "    y = y.numpy().reshape((1, img_rows, img_cols, channels))\n",
        "\n",
        "    # Get predictions for those images\n",
        "    x_transform = generator_g.predict(x)\n",
        "    y_transform = generator_f.predict(y)\n",
        "\n",
        "    # Get reconstruction for those images\n",
        "    x_reconstruct = generator_f.predict(x_transform.reshape((1, img_rows, img_cols, channels)))\n",
        "    y_reconstruct = generator_g.predict(y_transform.reshape((1, img_rows, img_cols, channels)))\n",
        "\n",
        "    plt.figure(figsize=(9*size, 20*size))\n",
        "\n",
        "    images = [x[0], x_transform[0], x_reconstruct[0],  y[0], y_transform[0], y_reconstruct[0]]\n",
        "\n",
        "    if setting == 'monet': \n",
        "      title = ['X (monet)', 'X transform', 'X reconstruct', 'Y (real)', 'Y transform', 'Y reconstruct']\n",
        "    elif setting == 'apple': \n",
        "      title = ['X (apple)', 'X transform', 'X reconstruct', 'Y (orange)', 'Y transform', 'Y reconstruct']\n",
        "    else: \n",
        "      title = ['X (MNIST)', 'X transform', 'X reconstruct', 'Y (SHVN)', 'Y transform', 'Y reconstruct']\n",
        "\n",
        "    for i in range(6):\n",
        "        plt.subplot(1, 6, i+1)\n",
        "        plt.imshow(images[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "        plt.title(title[i])\n",
        "    plt.tight_layout()\n",
        "    if name != None: plt.savefig('results_' + setting + '/' + name, bbox_inches = 'tight')\n",
        "    plt.show()\n",
        "\n",
        "if hot_start: \n",
        "  generator_g.load_weights('models_' + setting + '/'   + 'generator_g.h5')\n",
        "  generator_f.load_weights('models_' + setting + '/'   + 'generator_f.h5')\n",
        "  discriminator_x.load_weights('models_' + setting + '/'   + 'discriminator_x.h5')\n",
        "  discriminator_y.load_weights('models_' + setting + '/'   + 'discriminator_y.h5')\n",
        "\n",
        "for _ in range(1):\n",
        "    generate_images2(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMkF_M5PF-El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_length = len([x for x in iter(train_x)])\n",
        "y_length = len([y for y in iter(train_y)])\n",
        "print('train_x contains {} images'.format(x_length))\n",
        "print('train_y contains {} images'.format(y_length))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gPM73sAi8Svs",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "epochs = 50\n",
        "generate_images_epoch = 1\n",
        "batch_size = 1\n",
        "epoch_images = int( int( min(x_length, y_length) ) / batch_size)\n",
        "#epoch_images = 200\n",
        "\n",
        "# Timer\n",
        "start = time.time()\n",
        "\n",
        "# Manually loop through epochs\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    #LAMBDA2 = 2*LAMBDA2 / (2+epoch)\n",
        "    #upscale_discriminator = upscale_discriminator*1.1\n",
        "\n",
        "    # Each batch\n",
        "    for k, ((real_x, x_label), (real_y, y_label)) in tqdm(enumerate(tf.data.Dataset.zip((train_x.batch(batch_size), train_y.batch(batch_size)))), total = epoch_images):\n",
        "      \n",
        "        if k == epoch_images: \n",
        "          break\n",
        "        \n",
        "        # Train step\n",
        "        step(tf.reshape(real_x, (batch_size  , img_rows, img_cols, channels)), tf.reshape(real_y, (batch_size, img_rows, img_cols, channels)))\n",
        "    \n",
        "    # View progress\n",
        "    if epoch % generate_images_epoch == 0: \n",
        "      print('Every {} epoch generating images:'.format(generate_images_epoch))\n",
        "      name = 'cycle_epoch_{}_{}'.format(epoch,'training')\n",
        "      generate_images2(size=1.5, name = name)\n",
        "    \n",
        "    generator_g.save('models_' + setting + '/'   + 'generator_g.h5')\n",
        "    generator_f.save('models_' + setting + '/'   + 'generator_f.h5')\n",
        "    discriminator_x.save('models_' + setting + '/'   + 'discriminator_x.h5')\n",
        "    discriminator_y.save('models_' + setting + '/'   + 'discriminator_y.h5')\n",
        "\n",
        "    # Time taken\n",
        "    dif_time = time.time() - start\n",
        "    print('Time taken: {}m {}s'.format(round(dif_time // 60), round(dif_time  % 60)))\n",
        "\n",
        "    generator_g.save('models_' + setting + '/'   + 'generator_g_end.h5')\n",
        "    generator_f.save('models_' + setting + '/'   + 'generator_f_end.h5')\n",
        "    discriminator_x.save('models_' + setting + '/'   + 'discriminator_x_end.h5')\n",
        "    discriminator_y.save('models_' + setting + '/'   + 'discriminator_y_end.h5')\n",
        "\n",
        "print('\\n##################\\n#### FINISHED ####\\n##################\\n\\nTotal Time taken: {}m {}s'.format(round(dif_time // 60), round(dif_time  % 60)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNqBiTnRLC1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "    name = 'end_cycle_epoch_{}_{}'.format(epoch,i)\n",
        "    generate_images2(size=1.5, name = name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrAxzMCLVxd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in range(5):\n",
        "    generate_images(size=1.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9kc-WHtQHmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('End')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDmgqaLc6Cnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_g.save('models/' + setting + 'generator_g.h5')\n",
        "generator_f.save('models/' + setting + 'generator_f.h5')\n",
        "discriminator_x.save('models/' + setting + 'discriminator_x.h5')\n",
        "discriminator_y.save('models/' + setting + 'discriminator_y.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD7WpWpxEkYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwzL0RC_SVrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}